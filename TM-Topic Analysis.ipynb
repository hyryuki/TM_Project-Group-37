{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d700aad9",
   "metadata": {},
   "source": [
    "# Topic Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f9609",
   "metadata": {},
   "source": [
    "# Motivation using this training datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4e1e4",
   "metadata": {},
   "source": [
    "I use three different training datasets that are devided into restaurant review, book review, and movie review that are taken from Kaggle.The test data contains texts that show topic of interest in review about restaurant, book, and movie. The reason for chosing the training datasets because it cover relevant examples that can be used to train the model. In addition to that, the number of data avaiable within the training datasets are relatively big which could be a good representation of the topics and diverse enought to see different presepective related to each topic. A study by Mikolov et al. (2013) shoed that increasing number of features in dataset can improve the performance of the model and this is what we aimed for, to look for good model to do NLP tasks. Moreover, Jurgens et al. (2017) has shown that a diverse training dataset can also improve the performance of a analysis model.\n",
    "\n",
    "Source: \n",
    "1. Movie review:  https://www.kaggle.com/datasets/columbine/imdb-dataset-sentiment-analysis-in-csv-format\n",
    "2. Book review: https://www.kaggle.com/datasets/meetnagadia/amazon-kindle-book-review-for-sentiment-analysis\n",
    "3. Restaurant Review: https://www.kaggle.com/code/apekshakom/sentiment-analysis-of-restaurant-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad29f5b9",
   "metadata": {},
   "source": [
    "## Motivation for Unsupervised Model for Topic Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3616639",
   "metadata": {},
   "source": [
    "While searching for suitable training datasets that match the topic of the given dataset, I observed that none of the entries in the training datasets provide any explicit labels for the topics. As per the lecture, when labeled data is not available, or the labels are missing, an unsupervised model is the appropriate solution. Furthermore, the application of supervised techniques may not be appropriate in this context as their objective is different from that of unsupervised techniques, which aim to identify latent topics within a collection of documents. Hence, unsupervised topic modeling techniques would be more appropriate for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e521cd",
   "metadata": {},
   "source": [
    "## 1. LDA \n",
    "\n",
    "***Motivation*** : The datasets provided, namely the restaurant review dataset, the book review dataset, and the movie review dataset, contain a limited number of reviews. However, as these reviews may be related to a certain topic, it is important to identify how likely a document is related to a hidden or latent topic. Latent Dirichlet Allocation (LDA) is an appropriate topic modelling technique for this task, as it helps to identify the most frequently mentioned topics within the documents. Additionally, LDA is well-suited for small datasets, such as the ones provided. Therefore, utilizing LDA for these datasets can provide insights into the latent topics discussed within the reviews.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c95147",
   "metadata": {},
   "source": [
    "## 1.1 Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34805847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from itertools import combinations\n",
    "\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d28b2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "restaurant_reviews = pd.read_csv('Data/Restaurant_Reviews.tsv', delimiter='\\t').rename(columns={'Review': 'text'})\n",
    "movie_reviews = pd.read_csv('Data/movie_review.csv')\n",
    "book_reviews = pd.read_csv('Data/book_reviews.csv')\n",
    "test_set = pd.read_csv(\"data/sentiment-topic-final-test.tsv\", delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c6ffb",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3edb5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [stemmer.stem(token) for token in tokens if token not in stop_words and token.isalnum()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b847e47",
   "metadata": {},
   "source": [
    "def word_match(topic1, topic2):\n",
    "    word1 = set(topic1)\n",
    "    word2 = set(topic2)\n",
    "    return len(word1 & word2) / len(word1 | word2)\n",
    "\n",
    "def topic_diversity(lda_model):\n",
    "    topics = lda_model.show_topics(num_topics=-1, formatted=False)\n",
    "    top_words = [[word[0] for word in topic[1]] for topic in topics]\n",
    "    similarities = [word_match(pair[0], pair[1]) for pair in combinations(top_words, 2)]\n",
    "    return sum(similarities) / len(similarities)\n",
    "\n",
    "\n",
    "datasets = ['restaurant_reviews', 'book_reviews', 'movie_reviews']\n",
    "\n",
    "corpora_dict = {}\n",
    "corpora_corpus = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    corpus = [preprocess_text(doc) for doc in globals()[dataset]['text']]\n",
    "    corpora_dict[dataset] = corpora.Dictionary(corpus)\n",
    "    corpora_corpus[dataset] = [corpora_dict[dataset].doc2bow(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5bbc18",
   "metadata": {},
   "source": [
    "## 1.2 Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2c5893b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant_Reviews perplexity on test set: -94.72159922122955\n",
      "\n",
      "Restaurant_Reviews LDA Topics:\n",
      "Topic 0: back go place wo would come think recommend food probabl\n",
      "Topic 1: good food great delici servic time disappoint select price one\n",
      "Topic 2: great good bland experi time flavor bad dinner wonder salad\n",
      "Topic 3: place like go eat nice love spot lunch know spici\n",
      "Topic 4: time wait servic never back great go say server came\n",
      "Topic 5: servic food place slow friendli terribl waitress server mediocr return\n",
      "Topic 6: place food amaz best love awesom want tri minut pizza\n",
      "Topic 7: good food realli restaur servic order place excel qualiti expect\n",
      "Topic 8: friendli tast great staff pretti servic worst buffet food ever\n",
      "Topic 9: like definit fri realli restaur one atmospher better food ever\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashillarisautami/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Restaurant_Reviews LDA Topic Diversity: 0.08086228643504187\n",
      "Book_Reviews perplexity on test set: -475.3260098501693\n",
      "\n",
      "Book_Reviews LDA Topics:\n",
      "Topic 0: printer paper print page color jam hp puzzl divorc document\n",
      "Topic 1: movi watch one film like make good time bad stori\n",
      "Topic 2: bed air mattress night inflat sleep flea airb 3d pump\n",
      "Topic 3: toy song album play cd son music great love one\n",
      "Topic 4: work player get buy softwar time play one tri problem\n",
      "Topic 5: use one work product would good get great buy ear\n",
      "Topic 6: music great cd track show video danc listen like ipod\n",
      "Topic 7: book read stori one great would like good time interest\n",
      "Topic 8: card test concert toefl bowl holder bike well hand mac\n",
      "Topic 9: scanner puzzl stewart la max patrick de produc memori vista\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashillarisautami/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Book_Reviews LDA Topic Diversity: 0.044402400336352864\n",
      "Movie_Reviews perplexity on test set: -630.8721218354841\n",
      "\n",
      "Movie_Reviews LDA Topics:\n",
      "Topic 0: murphi eddi elvi pari french kelli funni chaplin mari gene\n",
      "Topic 1: snake woodi allen sarn scarlett vidal peebl wodehous astair mississippi\n",
      "Topic 2: episod seri freddi holli season harri batman ranger melodi stoog\n",
      "Topic 3: sam trek betti che rick pacino episod laura steve kirk\n",
      "Topic 4: br movi film one like time good charact make watch\n",
      "Topic 5: game music holm band play wagner elizabeth judi kramer player\n",
      "Topic 6: bug wood ant charl ray foxx giallo gere anna lane\n",
      "Topic 7: rat edi match detect eugen ricci wrestlemania wwe vanc charley\n",
      "Topic 8: barney stanwyck loy franki becki mormon ford grandson donald barbara\n",
      "Topic 9: scroog jane mclaglen fritton dicken din christma gustav sim bundl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashillarisautami/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movie_Reviews LDA Topic Diversity: 0.0011695906432748538\n"
     ]
    }
   ],
   "source": [
    "num_topics = 10\n",
    "perplexity_scores = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    dictionary = corpora_dict[dataset]\n",
    "    lda_model = models.LdaModel(corpora_corpus[dataset], num_topics=num_topics, id2word=dictionary, passes=50, alpha='auto', eta='auto')\n",
    "    corpus = [dictionary.doc2bow(preprocess_text(doc)) for doc in test_set['text']]\n",
    "    perplexity = lda_model.log_perplexity(corpus)\n",
    "    print(f\"{dataset.title()} perplexity on test set: {perplexity}\")\n",
    "    perplexity_scores.append(perplexity)\n",
    "\n",
    "\n",
    "    # Print the top words for each topic\n",
    "    print(f\"\\n{dataset.title()} LDA Topics:\")\n",
    "    for i, topic in lda_model.show_topics(num_topics=num_topics, formatted=False):\n",
    "        print(f\"Topic {i}: {' '.join([word[0] for word in topic])}\")\n",
    "        \n",
    "    vis_data = gensimvis.prepare(lda_model, corpora_corpus[dataset], dictionary)\n",
    "    pyLDAvis.display(vis_data)\n",
    "    \n",
    "    print(f\"\\n{dataset.title()} LDA Topic Diversity: {topic_diversity(lda_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c08a10",
   "metadata": {},
   "source": [
    "## 1.3 Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3c7e75",
   "metadata": {},
   "source": [
    "Based on the LDA results, the diversity score for the three domains suggests that restaurant reviews have a wider range of topics discussed compared to the other domains. However, the perplexity score for the restaurant reviews domain was the highest, indicating that the LDA model struggled the most in predicting topics within this domain. On the other hand, the book review domain had the lowest perplexity score, suggesting that the LDA model performed better in detecting and predicting underlying topics in this domain.\n",
    "\n",
    "Overall, the LDA model performed best on the restaurant reviews domain for topic modelling, despite its high perplexity score. It is possible that the restaurant reviews dataset had higher quality data and covered more relevant words to indicate certain topics, leading to its better performance compared to the other domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9511f9b",
   "metadata": {},
   "source": [
    "## 2. NMF \n",
    "\n",
    "***Motivation*** : NFM is similar to LDA where both of them are unsupervised topic modelling analysis system. Non-negative Matrix Factorization (NMF) is a popular topic modeling technique that uses probability distribution for the topic over the words. The purpose of NMF is to uncover the underlying topics in a text corpus. In this study, there are three main reasons why NMF was chosen as the method for topic modeling.\n",
    "\n",
    "Firstly, the primary objective was to identify the underlying topics in the restaurant, book, and movie review datasets. NMF is a suitable method for this purpose since it aims to discover the latent topics that are present in the text data.\n",
    "\n",
    "Secondly, the datasets used in this study are of moderate size. NMF is an appropriate technique for topic modeling in moderate-sized datasets. Therefore, it is a practical and efficient method for this study.\n",
    "\n",
    "Lastly, the training datasets were taken from 'chosen' topics, and it is assumed that there is a related overlapping topic within the datasets. This nature of topic within NMF makes it an ideal choice for topic modeling in this study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9a027f",
   "metadata": {},
   "source": [
    "## 2.1 Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9ad5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text).lower()\n",
    "    return text\n",
    "\n",
    "restaurant_reviews[\"clean_text\"] = restaurant_reviews[\"text\"].apply(clean_text)\n",
    "book_reviews[\"clean_text\"] = book_reviews[\"text\"].apply(clean_text)\n",
    "movie_reviews[\"clean_text\"] = movie_reviews[\"text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1fccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 5\n",
    "\n",
    "# Train NMF model for restaurant reviews\n",
    "nmf_models = []\n",
    "for vectors in [restaurant_vectors, book_vectors, movie_vectors]:\n",
    "    nmf_model = NMF(n_components=num_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(vectors)\n",
    "    nmf_models.append(nmf_model)\n",
    "    \n",
    "nmf_restaurant, nmf_book, nmf_movie = nmf_models\n",
    "\n",
    "\n",
    "# Get the feature names from the vectorizer\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names from the vectorizer\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "num_topics = 10\n",
    "nmf_model = NMF(n_components=num_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(vectors)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Print topics\n",
    "for i, review_type in enumerate(review_types):\n",
    "    print(f\"Popular words in {review_type} Reviews:\")\n",
    "    for topic_idx, topic in enumerate(nmf_models[i].components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]\n",
    "        print(f\"Topic #{topic_idx}: {' '.join(top_words)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493e883",
   "metadata": {},
   "source": [
    "## 2.2 Test Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "777b22f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity scores:\n",
      "Restaurant reviews: 3.051355555507736\n",
      "Book reviews: 5.192539598545418\n",
      "Movie reviews: 6.886882970500702\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_set[\"clean_text\"] = test_set[\"text\"].apply(clean_text)\n",
    "test_vectors = vectorizer.transform(test_set[\"clean_text\"])\n",
    "\n",
    "num_topics = 5\n",
    "nmf_restaurant = NMF(n_components=num_topics, random_state=1, l1_ratio=.5).fit(restaurant_vectors)\n",
    "nmf_book = NMF(n_components=num_topics, random_state=1, l1_ratio=.5).fit(book_vectors)\n",
    "nmf_movie = NMF(n_components=num_topics, random_state=1, l1_ratio=.5).fit(movie_vectors)\n",
    "\n",
    "perplexity_restaurant = nmf_restaurant.reconstruction_err_ / test_vectors.shape[0]\n",
    "perplexity_book = nmf_book.reconstruction_err_ / test_vectors.shape[0]\n",
    "perplexity_movie = nmf_movie.reconstruction_err_ / test_vectors.shape[0]\n",
    "\n",
    "print(\"Perplexity scores:\")\n",
    "print(\"Restaurant reviews:\", perplexity_restaurant)\n",
    "print(\"Book reviews:\", perplexity_book)\n",
    "print(\"Movie reviews:\", perplexity_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb50025",
   "metadata": {},
   "source": [
    "## 2.3 Results Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3edf19e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def calculate_topic_diversity(nmf_model, vectors):\n",
    "    num_topics = nmf_model.n_components\n",
    "    js_divergences = []\n",
    "    for i in range(num_topics):\n",
    "        for j in range(i+1, num_topics):\n",
    "            topic1 = nmf_model.components_[i]\n",
    "            topic2 = nmf_model.components_[j]\n",
    "            js_div = jensenshannon(topic1, topic2)\n",
    "            js_divergences.append(js_div)\n",
    "    mean_jsd = sum(js_divergences) / len(js_divergences)\n",
    "    return mean_jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a99412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic diversity for Restaurant reviews: 0.7379099680768332\n",
      "Topic diversity for Book reviews: 0.6689850721887485\n",
      "Topic diversity for Movie reviews: 0.5964365433673029\n"
     ]
    }
   ],
   "source": [
    "review_types = [\"Restaurant\", \"Book\", \"Movie\"]\n",
    "review_vectors = [restaurant_vectors, book_vectors, movie_vectors]\n",
    "\n",
    "# Train NMF models and compute topic diversity for each\n",
    "for i, review_type in enumerate(review_types):\n",
    "    nmf_model = NMF(n_components=num_topics, random_state=1, l1_ratio=.5).fit(review_vectors[i])\n",
    "    topic_diversity = calculate_topic_diversity(nmf_model, review_vectors[i])\n",
    "    print(f\"Topic diversity for {review_type} reviews: {topic_diversity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acf4ab",
   "metadata": {},
   "source": [
    "\n",
    "Based on the NMF results, the perplexity scores for the three domains suggest that the NMF model performed best on the restaurant reviews domain with the lowest perplexity score of 3.05. The book reviews domain had the second-lowest perplexity score of 5.20, while the movie reviews domain had the highest perplexity score of 6.90, indicating that the NMF model struggled the most in predicting topics within this domain.\n",
    "\n",
    "The topic diversity scores suggest that the restaurant reviews domain had the highest diversity of topics discussed with a score of 0.81, followed by the book reviews domain with a score of 0.73, and the movie reviews domain with a score of 0.72. This suggests that the restaurant reviews cover a wider range of topics compared to the other two domains.\n",
    "\n",
    "\n",
    "One possible explanation for this difference in performance is that the language used in restaurant reviews may be more straightforward and less ambiguous than the language used in book and movie reviews. Additionally, the topics that people write about in restaurant reviews may be more consistent and predictable than the topics that people write about in book and movie reviews, which can be more varied and subjective.\n",
    "\n",
    "Overall, the NMF model performed best on the restaurant reviews domain for topic modelling, with the lowest perplexity score and highest topic diversity score. It's possible that the restaurant reviews dataset had higher quality data and covered more relevant words to indicate certain topics, leading to the better performance of the NMF model compared to the other domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a8eafa",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ee840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# LDA data\n",
    "lda_perplexity_scores = [-94.95524405178271, -475.3260098501693, -630.8721218354841]\n",
    "lda_topic_diversity = [0.08086228643504187, 0.044402400336352864, 0.0011695906432748538]\n",
    "\n",
    "# NMF data\n",
    "nmf_perplexity_scores = [3.051355555507736, 5.192539598545418, 6.886882970500702]\n",
    "nmf_topic_diversity = [ 0.7379099680768332, 0.6689850721887485,  0.5964365433673029]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "# Plot perplexity scores \n",
    "axs[0, 0].bar(range(len(lda_perplexity_scores)), lda_perplexity_scores)\n",
    "axs[0, 0].set_xticks(range(len(lda_perplexity_scores)))\n",
    "axs[0, 0].set_xticklabels(['Restaurant', 'Book', 'Movie'])\n",
    "axs[0, 0].set_ylabel('Perplexity Score')\n",
    "axs[0, 0].set_title('LDA Perplexity Scores')\n",
    "\n",
    "# Plot topic diversity \n",
    "axs[0, 1].bar(range(len(lda_topic_diversity)), lda_topic_diversity)\n",
    "axs[0, 1].set_xticks(range(len(lda_topic_diversity)))\n",
    "axs[0, 1].set_xticklabels(['Restaurant', 'Book', 'Movie'])\n",
    "axs[0, 1].set_ylabel('Topic Diversity')\n",
    "axs[0, 1].set_title('LDA Topic Diversity')\n",
    "\n",
    "# Plot perplexity scores \n",
    "axs[1, 0].bar(range(len(nmf_perplexity_scores)), nmf_perplexity_scores)\n",
    "axs[1, 0].set_xticks(range(len(nmf_perplexity_scores)))\n",
    "axs[1, 0].set_xticklabels(['Restaurant', 'Book', 'Movie'])\n",
    "axs[1, 0].set_ylabel('Perplexity Score')\n",
    "axs[1, 0].set_title('NMF Perplexity Scores')\n",
    "\n",
    "# Plot topic diversity \n",
    "axs[1, 1].bar(range(len(nmf_topic_diversity)), nmf_topic_diversity)\n",
    "axs[1, 1].set_xticks(range(len(nmf_topic_diversity)))\n",
    "axs[1, 1].set_xticklabels(['Restaurant', 'Book', 'Movie'])\n",
    "axs[1, 1].set_ylabel('Topic Diversity')\n",
    "axs[1, 1].set_title('NMF Topic Diversity')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "\n",
    "# Save the figure as a PNG image\n",
    "plt.savefig('topic_model_results.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e68a3",
   "metadata": {},
   "source": [
    "Comparing the LDA and NMF results, the two models had different performance outcomes depending on the  domains. For LDA, the restaurant reviews domain had the highest topic diversity score of 0.088, and  the movie reviews domain with a score of 0.043, lastly the book reviews domain with the lowest score of 0.037. On the other hand, the NMF model had the highest topic diversity score for the restaurant reviews domain with a score of 0.814, book reviews domain with a score of 0.731, and the movie reviews domain with a score of 0.725. For predicting unseen data, NMF performs better for all three domain. It is because it achieve lower score. \n",
    "\n",
    "Overall, the performance of the two models  depends on the domain being analyzed. Both models performed well on the restaurant reviews domain, while the LDA model had better performance on the book reviews and movie reviews domains in terms of perplexity scores. The NMF model had higher topic diversity scores across all three domains, suggesting that it can capture a wider range of topics in the data compared to the LDA model. But, it can be said that NMF outperformed LDA as it generates better results that match the out goal which is iddentifying underlying goals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd256d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
